
Maintenant que l'on a déterminé que l'on souhaite travailler sur un les couples $\thetaB$ et $\thetaA$, il nous faut déterminer un critère pour déterminer quel couple est plus judicieux pour la méilleure estimation en pratique des paramètres de régularité locale.

% L'heuristique est la suivante : dans les simulations, il est possible de faire 200 simulations de monte carlo et d'obtenir le $\Delta^*$ le plus proche du $\Delta$ optimal pour estimer la régularité. Dans la pratique, obtenir un tel $\Delta$ optimal n'est pas réaliste. On ne connait pas la régularité du processus que l'on souhaite estimer. L'idée est donc de favoriser le couple de $\theta(u,v)$ qui possède le plus grand plateau autour du $\Delta^*$ pour le risque euclidien \emph{si l'écart de risque enclidien entre les deux couples n'est pas trop important}. Si l'un est beaucoup plus performant que l'autre, on choisira le plus performant. Mais si la performance des deux est à peu près équivalente, autant sélectionner celui qui dans la pratique (c'est-à-dire sans avoir 200 réplications indépendantes) nous donnera le plus de flexibilité sur l'erreur commise en sélectionnant un $\Delta$ autour du $\Delta^*$ dû à la fluctuation statistique.
L'approche adoptée est la suivante : dans un contexte de simulations, il est possible de mener 200 simulations de Monte Carlo pour déterminer une valeur de $\Delta$ la plus proche du $\Delta^*$ optimal pour estimer la régularité. Cependant, dans la réalité, atteindre une valeur $\Delta$ optimale est peu probable car nous ne possédons pas d'information sur la régularité du processus que nous cherchons à estimer. Par conséquent, l'idée consiste à privilégier le couple $\theta(u,v)$ qui présente le plus grand plateau autour de $\Delta^*$ sur la base du risque euclidien, à condition que la différence de risque entre les deux couples ne soit pas trop significative. Si l'un des couples se distingue nettement en termes de performance, alors il est logique de le sélectionner. Cependant, si les performances des deux couples sont relativement similaires, il est préférable d'opter pour celui qui offre davantage de flexibilité dans la pratique (c'est-à-dire sans avoir recours à 200 réplications indépendantes) pour gérer les erreurs lors de la sélection d'un $\Delta$ autour de $\Delta^*$, compte tenu des fluctuations statistiques.

\subsection{Détermination d'un seuil pour l'équivalence de risque quadratique}

Il nous faut maintenant déterminer ce que l'on considère comme étant deux risques "équivalents". Pour cela on va déterminer pour différentes valeurs du véritable $H$ le seuil $\varepsilon$ sur le risque tel que $R\cindexA(\Delta + \delta) + \varepsilon$ induit une erreur d'au maximum $10$\% sur le H estimé. On viendra ensuite déterminer les $\delta$ qui en moyenne correspondent à ce seuil $\varepsilon$ pour les différentes valeurs de $H$.

\subsection{Détermination du meilleur couple à risque \og équivalent \fg}

\subsubsection{en utilisant les pentes}


Une méthode possible serait de définir la pente à gauche et la pente à droite de la façon suivante :

\begin{align*}
	a_g : \Delta, \delta & \mapsto \frac{R(\Delta) - R(\Delta - \delta)}{\delta} \\
	a_d : \Delta, \delta & \mapsto \frac{R(\Delta + \delta) - R(\Delta)}{\delta}
\end{align*}
On peut définir les pénalisations suivantes pour déterminer le meilleur couple à risque équivalent en terme de plateau, en pénalisant les larges différence entre la pente à gauche et à droite :

\begin{equation*}
	m_q(\Delta, \delta) = \frac{a_g^2(\Delta, \delta) + a_d^2(\Delta, \delta)}{2}
\end{equation*}

\subsubsection{en utilisant les valeurs de risque}
une autre méthode est de regarder :

\begin{align*}
	R_2(\Delta^*_2) & \geq R_1(\Delta^*_1)                                      \\
	dR              & = \bigl\vert R_1(\Delta^*_1) - R_2(\Delta^*_2) \bigr\vert
\end{align*}
on compare désormais les valeurs de :

\begin{align*}
	r_g^{[2]} & = R_2(\Delta^*_2 - \delta) - dR \\
	r_d^{[2]} & = R_2(\Delta^*_2 + \delta) - dR
\end{align*}
aux valeurs

\begin{align*}
	r_g^{[1]} & = R_1(\Delta^*_1 - \delta) \\
	r_d^{[1]} & = R_1(\Delta^*_1 + \delta)
\end{align*}
avec le critère de sélection suivant :

\begin{equation*}
	\argmin \bigl( \frac{r_g^{[1]} + r_d^{[1]}}{2}, \frac{r_g^{[2]} + r_d^{[2]}}{2}  \bigr)
\end{equation*}
Pour pénaliser les solutions où la pente à gauche est très différente de la pente à droite en magnitude, on peut considérer d'élever $r_g$ et $r_d$ au carré.

\begin{equation*}
	\argmin \bigl( \frac{(r_g^{[1]})^2 + (r_d^{[1]})^2}{2}, \frac{(r_g^{[2]})^2 + (r_d^{[2]})^2}{2}  \bigr)
\end{equation*}
\subsubsection{résultat}

\warn{
	Il est important de garder en tête le modèle dans lequel on s'est placé pour étudier le comportement du $\Delta$. La recommendation qui est faite pour la sélection du $\Delta$ est valable pour :

	\begin{itemize}
		\item $\operatorname{FAR}(1)$ construit à partir d'un $\operatorname{mfBm}(H, L)$
		\item la régularité donnée par $H(t)$, qui dans notre cas est $\mathcal C^\infty$ sur $[0,1]$
		\item le noyau de la relation auto-régressive $\beta$ est une fonction de classe $\mathcal C^{\infty}$ sur $]0, 1]$ et continue en $0$
		\item La dérivée de $H$ est $H' :t \mapsto \frac{2 e ^{-5(t-0.5)}}{\left(1 + e ^{-5(t-0.5)}\right)^2}$, la variation maximale de la régularité est atteinte en $\argmax\limits_{t \in [0,1]} H'(t) = \frac 1 2$ avec $H'(\frac 1 2)=\frac 1 2$
		\item La régularité est monotone et strictement croissante sur $[0,1]$
	\end{itemize}

	Trop s'éloigner de ces hypothèses pourrait demander d'analyser de nouveau le comportement du $\Delta$ dû aux propriétés de certaines de ces quantités qui aurrait pu influencer le résultat.
}
