\chapter{Détails techniques et théoriques}
\minitoc%

\section{Données fonctionnelles : formellement}
\label{annexe:fda-formel}
\input{content/annexe/theorie/fda/essentiel.tex}

\section{Régularité Locale}
\label{annexe:regularite-locale}
\input{content/annexe/theorie/regularite_locale-formel.tex}

\section{Dépendance Faible et LGN version faible}
\label{annexe:weak_dep}
\input{content/annexe/theorie/ts/main.tex}

\section{Continuité de Kolmogorov}
\label{annexe:continuite_kolmogorov}
\input{content/annexe/theorie/continuite_kolmogorov.tex}

\section{Estimation adaptative}
\label{annexe:estim_adapt}
\input{content/annexe/theorie/estimation_adaptative/main.tex}

\section{Mouvement Brownien}
\label{annexe:brownien}
\input{content/annexe/theorie/brownien.tex}

\section{Théorie de la base d'ondelettes}
\label{annexe:wavelet}
\input{content/annexe/theorie/wavelet.tex}

% ! ——————————————————————————————————————————— !

\chapter{Plus de détails sur l'étude du Risque}

\minitoc%

\section{Pourquoi viser l'estimation des couples d'incréments plutôt que la régularité}
\label{annexe:choix_risque_couple}
\input{content/annexe/risque/couple_risk.tex}

% \section{Détermination d'un critère de choix du diamètre $\Delta$ des intervalles à considérer pour l'estimation de la régularité locale}
% \input{content/annexe/risque/critere.tex}


\section{Peut-on considérer que tous les $\Delta$ conviennent ?}
\label{annexe:tous_theta_conviennent_borne_norme_theta}

Nous considérons le risque euclidien : $\mathcal R(\Theta, \Delta) = \mathds E \distnorme 2 {\widehat \Theta}{\widetilde \Theta}$. C'est un risque naturel à considérer pour une estimation conjointe de deux paramètres. Evidemment, nous ne disposons pas de la loi de $\distnorme 2 {\widehat \Theta}{\widetilde \Theta}$ c'est pourquoi nous calculons $\widehat {\mathcal R}(\Theta, \Delta) = \mathds E \distnorme 2 {\widehat \Theta}{\widetilde \Theta}$

Nous observons sur les différents graphes des risques de l'ordre de grandeur de $10^{-2}$ ou même de $10^{-3}$. La question que l'on se pose désormais est si il est raisonnable de penser que ne pas choisir le $\Delta^*$ optimal n'est pas si important dans l'estimation du couple $\Theta$.

Ce que nous allons observer est qu'il est tout de même préférable de bien déterminer le $\Delta$

\begin{equation}
	\theta(u,v) = \esperanceloi X { \bigl| X(v) - X(u) \bigr|^2 } \leq L_{J(\Delta)}^2 \bigl| v - u \bigr|^{2 H_{J(\Delta)}}
\end{equation}

sachant que l'on évalue :

\begin{equation}
	\textsf{soit }
	\thetaA = \begin{bmatrix} \theta(t_1, t_3) \\ \theta(t_1, t_2) \end{bmatrix}
\end{equation}
\begin{equation}
	\textsf{soit }
	\thetaB = \begin{bmatrix} \theta(t_1, t_3) \\ \theta(t_2, t_3) \end{bmatrix}
\end{equation}


avec :

\begin{equation}
	\begin{array}{ccc}
		|t_3 - t_1| & = \Delta
		\\
		|t_3 - t_2| & = \frac \Delta 2 & = |t_2 - t_1|
	\end{array}\label{eq:couples_diff_delta_value}
\end{equation}

et donc :

\begin{equation}
	\displaystyle
	\begin{array}{rclr}
		\norme 2 \Theta & =    & \sqrt{\theta_{13}^{\,2} + \theta_{12/23}^{\, 2}}
		\\
		                & \leq & \sqrt{ L_{J(\Delta)}^4 \bigl( \, \Delta^{4 H_{J(\Delta)}} \left[ 1 + \frac 1 2 \right]  \, \bigr) }
		\\
		                & =    & L_{J(\Delta)}^2 \cdot \Delta^{2H_{J(\Delta)}} \cdot \sqrt{\frac 3 2}
	\end{array}
\end{equation}

Et donc :

\begin{equation*}
	\norme 2 \Theta \leq L_{J(\Delta)}^2 \cdot \Delta^{2H_{J(\Delta)}} \cdot \sqrt{\frac 3 2}
\end{equation*}

On se réfère à ces bornes même si l'on étudie plutôt $\widetilde \Theta$ car on peut se ramener asymptotiquement à $\Theta$ par la loi des grands nombres grâce à la dépendance faible :

\begin{align}
	 &  & \norme 2 {\widetilde \Theta} & =                                                                                                                      & \norme 2 {\frac 1 N \sum_{i=1}^{N} \begin{bmatrix} | X_i(t_3) - X_i(t_1) |^2 \\ | X_i(t_3) - X_i(t_2) |^2 \end{bmatrix}} &  &
	\\
	 &  &                              & \overset {\textsf{LGN} + \textsf{dep. faible} + \textsf{norme } \mathcal C^0(\R 2 \backslash\{ 0\}) }{\tend N \infty } & \norme 2 \Theta \leq L_{J(\Delta)}^2 \cdot \Delta^{2H_{J(\Delta)}} \cdot \sqrt{\frac 3 2}                                &  &
\end{align}

\begin{rem}
	On peut remplacer le couple $(t_2, t_3)$ par $(t_1, t_2)$ dans la deuxième composante, l'argument reste valide, comme explicité dans l'équation \ref{eq:couples_diff_delta_value}}
\end{rem}

En utilisant les données de la simulation, $L = 1$, on obtient :

\begin{equation}
	\begin{array}{ccc}
		H_{J(\Delta)} = 0.4  & \implies & \norme 2 \Theta
		\begin{cases}
			\lesssim 3 \cdot 10^{-2} \quad & \Delta = 0.01
			\\
			\lesssim 3\cdot 10^{-1} \quad  & \Delta = 0.2
		\end{cases}
		\\\\
		H_{J(\Delta)} = 0.5  & \implies & \norme 2 \Theta
		\begin{cases}
			\lesssim 1 \cdot 10^{-2} \quad & \Delta = 0.01
			\\
			\lesssim 2\cdot 10^{-1} \quad  & \Delta = 0.2
		\end{cases}
		\\\\
		H_{J(\Delta)} = 0.6  & \implies & \norme 2 \Theta
		\begin{cases}
			\lesssim 5 \cdot 10^{-3} \quad & \Delta = 0.01
			\\
			\lesssim 2\cdot 10^{-1} \quad  & \Delta = 0.2
		\end{cases}
		\\\\
		H_{J(\Delta)} = 0.73 & \implies & \norme 2 \Theta
		\begin{cases}
			\lesssim 1 \cdot 10^{-3} \quad & \Delta = 0.01
			\\
			\lesssim 1\cdot 10^{-1} \quad  & \Delta = 0.2
		\end{cases}
	\end{array}
\end{equation}

Ainsi, la différence de risque entre l'optimum et le pire cas étant de l'odre de $10^{-2}$ dans un cas très sparse comme dans la figure \ref{fig:sparse_osef} et dans un cas raisonnablement dense on observe même des différences de l'ordre de $10^{-3}$ pour le plus régulier.

\begin{table}[H]
	\centering
	\begin{tabularx}{0.7\textwidth}{|cc|X|X|c|}
		\toprule
		\textbf{H} & $\mathbf{\lambda}$ & \textbf{Différence : } $\mathbf{\mathcal R_{max} - \mathcal R_{min}}$ & ordre de gradeur de la borne de $\norme 2 \Theta$ & ${\norme 2 \Theta}^2$ \\
		\midrule
		0.51       & 60                 & 3.3 $\cdot 10^{-2}$                                                   & $\Delta^* \simeq 0.2$ : $10^{-1}$                 & $10^{-2}$             \\
		0.51       & 210                & 1.1 $\cdot 10^{-2}$                                                   & $\Delta^* \simeq 0.2$ : $10^{-1}$                 & $10^{-2}$             \\
		\midrule
		0.6        & 60                 & 4.2 $\cdot 10^{-2}$                                                   & $\Delta^* \simeq 0.01$ : $10^{-3}$                & $10^{-6}$             \\
		0.6        & 210                & 1.2 $\cdot 10^{-2}$                                                   & $\Delta^* \simeq 0.01$ : $10^{-3}$                & $10^{-6}$             \\
		\midrule
		0.73       & 60                 & 1.2 $\cdot 10^{-2}$                                                   & $\Delta^* \simeq 0.01$ : $10^{-3}$                & $10^{-6}$             \\
		0.73       & 210                & 5.4 $\cdot 10^{-3}$                                                   & $\Delta^* \simeq 0.01$ : $10^{-3}$                & $10^{-6}$             \\
		\bottomrule
	\end{tabularx}
	\caption{Ordre de grandeur des différences entre le risque euclidien minimum et maximum pour $\Delta \in [0.01, 0.2]$ et la norme de la cible}
	\label{tab:ordre_grandeur_diff_R_norme}
	\addcontentsline{lot}{table}{\numberline{} Comparaison des ordres de grandeur de la norme de la quantité ciblée $\widetilde \Theta$ et de différence entre le risque optimal et maximal.}
\end{table}

\noindent Étant donné que le risque utilisé est homogène à la norme euclidienne au carré, on ne peut dire, du point de vue du risque euclidien, que l'on peut prendre n'importe quel $\Delta$ dans $[0.01, 0.2]$ sans trop de conséquences.
Ce tableau vient motiver la section suivante sur le choix du risque à considérer pour la détermination d'un $\Delta$ optimal. Si la norme de notre cible varie avec $\Delta$, une idée est de plutôt considérer la qualité de l'estimation, relativement à la norme de la cible.



\section{Choix du risque : absolu ou relatif ?}
\label{annexe:choix-du-rique}

\subsection{Distance Euclidienne}

Afin de quantifier la qualité de l'estimation conjointe du couple de $\theta$, il est raisonnable de considérer la distance euclidienne usuelle pour des vecteurs de $\R 2$

\begin{equation*}
	R(\Theta, \Delta) = {\distnorme 2 {\widehat \Theta(\Delta)} {\widetilde \Theta(\Delta)}}^2
\end{equation*}

% et on nomme $R\cindexA(\Delta) = R( \thetaA , \, \Delta \, )$ et $R\cindexB(\Delta) = R( \thetaB, \, \Delta \, )$

\subsection{Distance Euclidienne Relative}

On va cependant considérer le risque relatif à la norme de la quantité que l'on cible :

\begin{equation*}
	R(\Theta, \Delta) =\frac{ {\distnorme 2 {\widehat \Theta(\Delta)} {\widetilde \Theta(\Delta)}}^2}{ {\norme 2 {\widetilde \Theta(\Delta)}}^2 }
\end{equation*}

\question{Pourquoi considérer la distance euclidienne relative à la norme de la cible $\widetilde \Theta$ plutôt que la distance euclidienne classique qui est plus simple ?}

Le risque sert à déterminer la qualité de l'estimation du couple $\widetilde \Theta$ par $\widehat \Theta$ à un $\Delta$ donné. Il faut cependant garder à l'esprit que $\Theta$ est en réalité une fonction de $\Delta$ car la valeur de $t_1, t_2, t_3$ dépendent de $\Delta$. Ainsi \emph{la norme de $\widetilde \Theta$ va varier lorsque l'on fait varier $\Delta$}\footnote{il est possible d'obtenir plus de détails en annexe \ref{annexe:tous_theta_conviennent_borne_norme_theta}}. Les risques obtenus via la norme euclidienne sont des risques qui mesurent une différence absolue, mais alors avoir \emph{un risque plus petit qu'un autre n'a pas le même sens pour différents $\Delta$ en termes de qualité d'approximation}. C'est pourquoi nous considérons le risque relatif dans la détermination du critère du choix du $\Delta$.

On pourra cependant observer la différence entre le risque euclidien et le risque euclidien relatif à la norme de la cible en $\Delta$ sur les figures \ref{fig:sparse_osef} et \ref{fig:sparse_osef_rel}.


\begin{comment}
\section{Récapitulatif de la qualité des estimations pour la stratégie de \og lissage global \fg}
\input{content/annexe/risque/tables_glob.tex}
\end{comment}

\section{Etude de l'impact de la méthode de sélection de la fenêtre de pré-lissage sur le risque d'estimation des couples $\Theta$}


% 

\input{content/annexe/risque/h_glob_indiv/h_glob_vs_indiv_txt.tex}
\input{content/annexe/risque/h_glob_indiv/h_glob_vs_indiv_tables.tex}

\section{Gestion des valeurs extrêmes}


\section{Graphes : indiv/global \& valeurs extrêmes}
% graphs
% extremes vs non extremes
% indiv vs global
\pagebreak
\input{content/annexe/risque/h_glob_indiv/h_glob_vs_indiv_graphs.tex}



\section{Etude de l'impact de la méthode de prélissage sur l'estimation de la régularité et le $\Delta$ optimal}
\label{annexe:prelissage_impact}
\input{content/annexe/risque/prelissage.tex}

% ! ——————————————————————————————————————————— !

\chapter{Un peu d'Histoire}
\label{annexe:histoire}
\section{ Histoire des séries temporelles }
\input{content/annexe/histoire/histoire_ts.tex}
\pagebreak
\section{ Histoire des données fonctionnelles }
\input{content/annexe/histoire/histoire_fda.tex}
\pagebreak
% \section{Histoire du mouvement brownien et de ses applications}
% \input{content/annexe/histoire/histoire_brownien.tex}
% \pagebreak

% ! ——————————————————————————————————————————— !

\chapter{Algorithmes \& Implémentations}

\label{annexe:code}
\section{Algorithmes de simulation}

\input{content/annexe/algo/algo.tex}

%\pagebreak
%\section{Implémentation R}
%\label{annexe:code-R}
%\input{content/annexe/algo/code.tex}

