
Maintenant que l'on a déterminé que l'on souhaite travailler sur un les couples $\thetaB$ et $\thetaA$, il nous faut déterminer un critère pour déterminer quel couple est plus judicieux pour la méilleure estimation en pratique des paramètres de régularité locale.

% L'heuristique est la suivante : dans les simulations, il est possible de faire 200 simulations de Monte-Carlo et d'obtenir le $\Delta^*$ le plus proche du $\Delta$ optimal pour estimer la régularité. Dans la pratique, obtenir un tel $\Delta$ optimal n'est pas réaliste. On ne connait pas la régularité du processus que l'on souhaite estimer. L'idée est donc de favoriser le couple de $\theta(u,v)$ qui possède le plus grand plateau autour du $\Delta^*$ pour le risque euclidien \emph{si l'écart de risque enclidien entre les deux couples n'est pas trop important}. Si l'un est beaucoup plus performant que l'autre, on choisira le plus performant. Mais si la performance des deux est à peu près équivalente, autant sélectionner celui qui dans la pratique (c'est-à-dire sans avoir 200 réplications indépendantes) nous donnera le plus de flexibilité sur l'erreur commise en sélectionnant un $\Delta$ autour du $\Delta^*$ dû à la fluctuation statistique.
L'approche adoptée est la suivante : dans un contexte de simulations, il est possible de mener 200 simulations de Monte Carlo pour déterminer une valeur de $\Delta$ la plus proche du $\Delta^*$ optimal pour estimer la régularité. Cependant, dans la réalité, atteindre une valeur $\Delta$ optimale est peu probable car nous ne possédons pas d'information sur la régularité du processus que nous cherchons à estimer. Par conséquent, l'idée consiste à privilégier le couple $\theta(u,v)$ qui présente le plus grand plateau autour de $\Delta^*$ sur la base du risque euclidien, à condition que la différence de risque entre les deux couples ne soit pas trop significative. Si l'un des couples se distingue nettement en termes de performance, alors il est logique de le sélectionner. Cependant, si les performances des deux couples sont relativement similaires, il est préférable d'opter pour celui qui offre davantage de flexibilité dans la pratique (c'est-à-dire sans avoir recours à 200 réplications indépendantes) pour gérer les erreurs lors de la sélection d'un $\Delta$ autour de $\Delta^*$, compte tenu des fluctuations statistiques.

% \subsection{Détermination d'un seuil pour l'équivalence de risque quadratique}

% Il nous faut maintenant déterminer ce que l'on considère comme étant deux risques "équivalents". Pour cela on va déterminer pour différentes valeurs du véritable $H$ le seuil $\varepsilon$ sur le risque tel que $R\cindexA(\Delta + \delta) + \varepsilon$ induit une erreur d'au maximum $10$\% sur le H estimé. On viendra ensuite déterminer les $\delta$ qui en moyenne correspondent à ce seuil $\varepsilon$ pour les différentes valeurs de $H$.

% \subsection{Détermination du meilleur couple à risque \og équivalent \fg}

% A risques équivalents $R_1$ et $R_2$, on peut déterminer quel diamètre $\Delta$ recommander au praticien en sélectionnant celui qui possède le plus grand \og plateau \fg autour de l'optimum. On peut alors déterminer le diamètre à sélectionner via deux critères possibles :

% \subsubsection{en utilisant les pentes}


% La première méthode consiste à regarder les pentes à gauche et à droite du $\Delta^*$ optimal. On définit les pentes de la façon suivante :

% \begin{align*}
% 	a_g : \Delta, \delta & \mapsto \frac{R(\Delta) - R(\Delta - \delta)}{\delta} \\
% 	a_d : \Delta, \delta & \mapsto \frac{R(\Delta + \delta) - R(\Delta)}{\delta}
% \end{align*}
% On peut définir les pénalisations suivantes pour déterminer le meilleur couple à risque équivalent en terme de plateau, en pénalisant les larges différence entre la pente à gauche et à droite :

% \begin{equation*}
% 	m_q(\Delta, \delta) = \frac{a_g^2(\Delta, \delta) + a_d^2(\Delta, \delta)}{2}
% \end{equation*}

% \subsubsection{en utilisant les valeurs de risque}
% une autre méthode est de regarder directement les valeurs à gauche et à droite du $\Delta^*$ optimal. En supposant que :

% \begin{equation*}
% 	R_2(\Delta^*_2) \geq R_1(\Delta^*_1)
% \end{equation*}

% \begin{equation*}	
% 	dR = \bigl\vert R_1(\Delta^*_1) - R_2(\Delta^*_2) \bigr\vert
% \end{equation*}

% on compare désormais les valeurs recentrées :

% \begin{align*}
% 	r_g^{[2]} & = R_2(\Delta^*_2 - \delta) - dR \\
% 	r_d^{[2]} & = R_2(\Delta^*_2 + \delta) - dR
% \end{align*}

% aux valeurs du risque sur la courbe correspondant à l'autre couple d'incréments :

% \begin{align*}
% 	r_g^{[1]} & = R_1(\Delta^*_1 - \delta) \\
% 	r_d^{[1]} & = R_1(\Delta^*_1 + \delta)
% \end{align*}

% avec le critère de sélection suivant :

% % \begin{equation*}
% % 	\argmin \bigl( \frac{r_g^{[1]} + r_d^{[1]}}{2}, \frac{r_g^{[2]} + r_d^{[2]}}{2}  \bigr)
% % \end{equation*}
% \idee{Pour pénaliser les solutions où la pente à gauche est très différente de la pente à droite en magnitude, on peut considérer d'élever $r_g$ et $r_d$ au carré.}

% \begin{equation*}
% 	\argmin\limits_{[1] \textsf{ ou } [2]} \bigl( \frac{(r_g^{[1]})^2 + (r_d^{[1]})^2}{2}, \frac{(r_g^{[2]})^2 + (r_d^{[2]})^2}{2}  \bigr)
% \end{equation*}


% \subsubsection{résultat et détermination de la procédure de sélection du $\Delta$}
% \label{sec:proc_delta}


% \question{Quelle procédure est recommandée pour la sélectionner un $\Delta$ adapté pour l'estimation de la régularité locale ?}

% On va distinguer 2 cas : 
% \begin{enumerate}
% 	\item Le lissage des courbes a été effectué avec une fenêtre de lissage individuelle, sélectionnée par validation croisée sur chaque courbe : méthode optimale.
% 	\item Le lissage des courbes a été effectué avec une fenêtre de lissage globale, sélectionnée via la médiane des fenêtres de lissage sur les premières courbes déterminées par validation croisée\footnote{Notons qu'il ne faut pas sélectionner des courbes aléatoirement mais plutôt les premières courbes car les données ont de la dépendance.} : économie de calcul.
% \end{enumerate}


% \begin{itemize}
% 	\item \textbf{lissage individuel} :
% 	\begin{enumerate}
% 		\item 
% 	\end{enumerate}
% 	\item \textbf{lissage global} :
% 	\begin{enumerate}
% 		\item 
% 	\end{enumerate}
% \end{itemize}
